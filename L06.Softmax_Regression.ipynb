{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP3muToaBriU",
        "outputId": "abf0ecd5-2e81-41de-899e-2c5cf6bcdd59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 4.391642093658447\n",
            "epoch: 300, cost: 0.14399978518486023\n",
            "epoch: 600, cost: 0.06783723831176758\n",
            "epoch: 900, cost: 0.039094168692827225\n",
            "epoch: 1200, cost: 0.02520613744854927\n",
            "epoch: 1500, cost: 0.01745430752635002\n",
            "epoch: 1800, cost: 0.012690887786448002\n",
            "epoch: 2100, cost: 0.009556088596582413\n",
            "epoch: 2400, cost: 0.007385135628283024\n",
            "epoch: 2700, cost: 0.005821835249662399\n",
            "epoch: 3000, cost: 0.004661102779209614\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x_train = torch.tensor([[1,2,1,1],[2,1,3,2],[3,1,3,4],[4,1,5,5],[1,7,5,5],[1,2,5,6],[1,6,6,6],[1,7,7,7]], dtype=torch.float)\n",
        "y_train = torch.FloatTensor([[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]])\n",
        "\n",
        "W = torch.randn(4,3,requires_grad = True)\n",
        "b = torch.randn(1,3,requires_grad = True)\n",
        "\n",
        "optim = torch.optim.Adam([W,b], lr=0.1)\n",
        "\n",
        "for epoch in range(3001):\n",
        "    #h = torch.softmax(torch.mm(x_train, W) + b, dim=1)\n",
        "    h = (torch.mm(x_train, W)+b).softmax(dim=1)\n",
        "    #cost = torch.mean(torch.sum(-torch.log(h) * y_train, dim=1))\n",
        "    cost = (-torch.log(h)*y_train).sum(dim=1).mean()\n",
        "\n",
        "    optim.zero_grad()\n",
        "    cost.backward()\n",
        "    optim.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      if epoch%300 == 0:\n",
        "        print(f\"epoch: {epoch}, cost: {cost.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.mm(x_train, W), dim=1)\n",
        "#y_train\n",
        "torch.sum(-torch.log(h) * y_train, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buTHkNTuHv3j",
        "outputId": "0deec885-3d22-4948-ee86-660b7b6cbc1f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1976e+00, 7.3302e+00, 6.4939e+00, 6.6757e-06, 1.7218e-01, 4.6287e-03,\n",
              "        6.8681e+00, 7.2193e+00], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = torch.tensor([[1,11,10,9],[1,3,4,3],[1,1,0,1]], dtype=torch.float)\n",
        "h = (torch.mm(x_test, W) + b).softmax(dim=1)\n",
        "print(torch.argmax(h,dim=1))"
      ],
      "metadata": {
        "id": "h2CSmG-4LkWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "x_train = torch.tensor([[1,2,1,1],[2,1,3,2],[3,1,3,4],[4,1,5,5],[1,7,5,5],[1,2,5,6],[1,6,6,6],[1,7,7,7]], dtype=torch.float)\n",
        "y_train = torch.tensor([2,2,2,1,1,1,0,0], dtype=torch.long)\n",
        "\n",
        "model = torch.nn.Linear(4,3)\n",
        "W = torch.randn(4,3,requires_grad = True)\n",
        "b = torch.randn(1,3,requires_grad = True)\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(3001):\n",
        "    #h = torch.mm(x_train, W)+b\n",
        "    h = model(x_train)\n",
        "    cost = F.cross_entropy(h,y_train)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    cost.backward()\n",
        "    optim.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      if epoch%300 == 0:\n",
        "        print(f\"epoch: {epoch}, cost: {cost.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPv-w-aOMxIt",
        "outputId": "e1b2dd34-50f0-4dc9-fcb2-baefb1ee6149"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 2.0765700340270996\n",
            "epoch: 300, cost: 0.11452198028564453\n",
            "epoch: 600, cost: 0.04621659591794014\n",
            "epoch: 900, cost: 0.025005392730236053\n",
            "epoch: 1200, cost: 0.015652265399694443\n",
            "epoch: 1500, cost: 0.010673997923731804\n",
            "epoch: 1800, cost: 0.0076949805952608585\n",
            "epoch: 2100, cost: 0.005765048786997795\n",
            "epoch: 2400, cost: 0.004441535100340843\n",
            "epoch: 2700, cost: 0.003494447097182274\n",
            "epoch: 3000, cost: 0.0027941742446273565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Linear(4,3)\n",
        "for p in model.parameters():\n",
        "  print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CuO42XwPUUP",
        "outputId": "1669f0e6-0545-44ad-8535-ca2187051511"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.4771,  0.2248,  0.0249, -0.2131],\n",
            "        [ 0.1850,  0.3594, -0.1053,  0.2804],\n",
            "        [ 0.4363,  0.4105, -0.2854, -0.3020]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0550, -0.0755,  0.3820], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = torch.tensor([[1,11,10,9],[1,3,4,3],[1,1,0,1]], dtype=torch.float)\n",
        "h = model(x_test)\n",
        "print(torch.argmax(h,dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WufJAK1P4kn",
        "outputId": "138a6406-6a5e-4197-c1f0-171bcd5b5a79"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2])\n"
          ]
        }
      ]
    }
  ]
}